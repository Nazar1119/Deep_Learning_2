{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56d0b484-5441-4a36-a65f-f9d111b5a60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath('..')\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "from llm_providers.models.Answer import *\n",
    "from llm_providers.views import ollama as provider\n",
    "from llm_providers.models.ollama import OllamaOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9b7ee81-fdfd-4869-a82a-efc188d91ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "608163b0-c5c1-445a-8a6f-f258026dcfd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the colour of the bag on the chair</td>\n",
       "      <td>pink</td>\n",
       "      <td>image399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is at the right bottom</td>\n",
       "      <td>table</td>\n",
       "      <td>image1341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what are found on the rack</td>\n",
       "      <td>toy</td>\n",
       "      <td>image1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is left of printer</td>\n",
       "      <td>mirror</td>\n",
       "      <td>image529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the colour of television</td>\n",
       "      <td>black</td>\n",
       "      <td>image201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     question  answer   image_id\n",
       "0  what is the colour of the bag on the chair    pink   image399\n",
       "1                 what is at the right bottom   table  image1341\n",
       "2                  what are found on the rack     toy  image1320\n",
       "3                     what is left of printer  mirror   image529\n",
       "4            what is the colour of television   black   image201"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.read_csv('../../data/dataset-1/data_eval.csv')\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ef8aa91-8de9-4e26-86f2-826b00917ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM answering: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2494/2494 [08:32<00:00,  4.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "predictions, references = list(), list()\n",
    "data_gen = eval_df.iterrows()\n",
    "\n",
    "for idx, row in tqdm(data_gen, desc=\"LLM answering\", total=len(eval_df)):\n",
    "\n",
    "    answer = provider.answer(\n",
    "        query = ImageAnswer(\n",
    "            query=row['question'],\n",
    "            paths=[Path('../../data/dataset-1/images').resolve() / f\"{row['image_id']}.png\"],\n",
    "            other_dict=[{\n",
    "                'role': 'system',\n",
    "                'content': \"\\n\".join([\n",
    "                    \"# Role\",\n",
    "                    \"You are an AI assitant, that answer on user question for provided image\",\n",
    "                    \"\",\n",
    "                    \"# Instructions\",\n",
    "                    \"1. Answer short and clear.\",\n",
    "                    f\"2. Answer in {len(row['answer'].split(' '))} word, that exactly answer on user question\",\n",
    "                    \"\",\n",
    "                ])\n",
    "            }]\n",
    "        ),\n",
    "        model=\"ministral-3:14b\",\n",
    "        options=OllamaOptions(\n",
    "            temperature=0\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    predictions.append(answer.answer)\n",
    "    references.append(row['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9e23fbd-74f9-41eb-8ae2-b0e59014e86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/am790sp/hu2/modules/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load \n",
    "\n",
    "bertscore = load('bertscore')\n",
    "\n",
    "results = bertscore.compute(\n",
    "    predictions=predictions, \n",
    "    references=references, \n",
    "    model_type=\"distilbert-base-uncased\", \n",
    "    rescale_with_baseline=True, \n",
    "    lang='en'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c7346c1-40cd-48b2-8c4e-1a5332c29cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision': 0.3031761201779303,\n",
       " 'Reccal': 0.3751325358685759,\n",
       " 'F1': 0.3364317751703809}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = {\n",
    "    \"Precision\": np.mean(results['precision']).item(),\n",
    "    \"Reccal\": np.mean(results['recall']).item(),\n",
    "    \"F1\": np.mean(results['f1']).item(),\n",
    "}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52657312-4ec1-4abb-9119-c3b01ed5e694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe92dbeb-b954-4d2a-8461-7bde8f87a8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e2ae45-267a-42d3-8754-598405b3f1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5670246-e22d-416e-969d-40b2d829da66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bdeb98-1ca1-4ae0-bbd0-e58955933d78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
